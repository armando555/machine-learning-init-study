{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbBQz3ailXaq70khu1wT6v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdmartinev/ST1613-AppliedML-/blob/main/Semana03/Regresi%C3%B3n_log%C3%ADstica_churn_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1d6iPtgmKM5N2mtrWFb-SzLdGCwLWmxF9' -O data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1nOuLnSHS05",
        "outputId": "9dcc2544-9479-400a-d7d0-2bd6a2d6c3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-20 13:28:04--  https://docs.google.com/uc?export=download&id=1d6iPtgmKM5N2mtrWFb-SzLdGCwLWmxF9\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.214.101, 173.194.214.138, 173.194.214.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.214.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c0tfolcti8g1oidu8uk0qn1lgsn4fqjn/1681997250000/15315348669826032119/*/1d6iPtgmKM5N2mtrWFb-SzLdGCwLWmxF9?e=download&uuid=8a50bad0-7726-4f24-bf22-2da5cd083706 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-20 13:28:04--  https://doc-0g-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c0tfolcti8g1oidu8uk0qn1lgsn4fqjn/1681997250000/15315348669826032119/*/1d6iPtgmKM5N2mtrWFb-SzLdGCwLWmxF9?e=download&uuid=8a50bad0-7726-4f24-bf22-2da5cd083706\n",
            "Resolving doc-0g-6c-docs.googleusercontent.com (doc-0g-6c-docs.googleusercontent.com)... 173.194.218.132, 2607:f8b0:400c:c14::84\n",
            "Connecting to doc-0g-6c-docs.googleusercontent.com (doc-0g-6c-docs.googleusercontent.com)|173.194.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 977501 (955K) [text/csv]\n",
            "Saving to: ‘data.csv’\n",
            "\n",
            "data.csv            100%[===================>] 954.59K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-04-20 13:28:05 (28.2 MB/s) - ‘data.csv’ saved [977501/977501]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YO75M4EHFD6"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import HTML\n",
        "\n",
        "sys.path.append(\"code/.\")\n",
        "\n",
        "#import mglearn\n",
        "from IPython.display import display\n",
        "#from plotting_functions import *\n",
        "\n",
        "\n",
        "# Preprocessing and pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.stats import reciprocal\n",
        "\n",
        "# train test split and cross validation\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge, Lasso, LogisticRegression\n",
        "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import (\n",
        "    MinMaxScaler,\n",
        "    OneHotEncoder,\n",
        "    OrdinalEncoder,\n",
        "    StandardScaler,\n",
        "    PolynomialFeatures,\n",
        ")\n",
        "pd.set_option(\"display.max_colwidth\", 200)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos los datos y procesamos algunas columnas\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Modificamos la variable 'TotalCharges' a tipo numérico\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
        "\n",
        "# Inlcuir guiones bajos en valores como No internet service\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "string_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
        "\n",
        "for col in string_columns:\n",
        "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
        "\n",
        "df.drop('customerid',axis=1,inplace=True)\n",
        "\n",
        "#Separar los datos en entrenamiento, validación y test\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=1)\n",
        "\n",
        "#Definir características y variable objetivo\n",
        "X_train = train_df.drop(columns=[\"churn\"])\n",
        "y_train = train_df[\"churn\"]\n",
        "\n",
        "X_test = test_df.drop(columns=[\"churn\"])\n",
        "y_test = test_df[\"churn\"]\n",
        "\n",
        "#Índices de las columnas numéricas y categ+oricas\n",
        "cat_cols = X_train.select_dtypes(include=object).columns\n",
        "num_cols = X_train.select_dtypes(include=np.number).columns\n"
      ],
      "metadata": {
        "id": "fEVkm1f5HjbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(\n",
        "    steps=[(\"scaler\", StandardScaler())]\n",
        ")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, num_cols),\n",
        "        (\"cat\", categorical_transformer, cat_cols),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "z_MffvZsJNnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos el clasificador base\n",
        "logreg_base = LogisticRegression()\n",
        "clf_logreg = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", logreg_base)])\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'classifier__C': np.logspace(-4, 4, 20),\n",
        "    'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "}\n",
        "\n",
        "search_logreg = GridSearchCV(clf_logreg, param_grid, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "search_logreg.fit(X_train, y_train)\n",
        "print(search_logreg)\n",
        "print(search_logreg.best_params_)\n",
        "\n",
        "# Obtengamos el accuracy para la regresión logística \n",
        "print('Modelo regresión logística')\n",
        "print(f'Accuracy: {search_logreg.score(X_test, y_test)}')"
      ],
      "metadata": {
        "id": "bYx_sFP4Jytx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ba0543-8714-4466-f10d-6da82afc7b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "900 fits failed out of a total of 2000.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
            "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
            "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.73003195        nan 0.73003195 0.73003195\n",
            " 0.73003195 0.73003195 0.73003195 0.73003195        nan        nan\n",
            "        nan        nan        nan 0.80315776 0.80315776        nan\n",
            " 0.80315776 0.80351284        nan        nan 0.73003195        nan\n",
            " 0.73003195 0.73003195 0.73003195 0.7367763  0.73003195 0.73003195\n",
            "        nan        nan        nan        nan        nan 0.80315776\n",
            " 0.80315776        nan 0.80315776 0.80333522        nan        nan\n",
            " 0.73003195        nan 0.73003195 0.75008944 0.75008944 0.77298334\n",
            " 0.75008944 0.75008944        nan        nan        nan        nan\n",
            "        nan 0.80315776 0.80315776        nan 0.80315776 0.80333522\n",
            "        nan        nan 0.73003195        nan 0.73003195 0.78700601\n",
            " 0.78700601 0.7928629  0.78700601 0.78700601        nan        nan\n",
            "        nan        nan        nan 0.80315776 0.80315776        nan\n",
            " 0.80315776 0.80351284        nan        nan 0.78327552        nan\n",
            " 0.7587832  0.7967688  0.7967688  0.79836596 0.7967688  0.7967688\n",
            "        nan        nan        nan        nan        nan 0.80315776\n",
            " 0.80315776        nan 0.80315776 0.80333522        nan        nan\n",
            " 0.79215257        nan 0.79250766 0.80244822 0.80244822 0.80280283\n",
            " 0.80244822 0.80244822        nan        nan        nan        nan\n",
            "        nan 0.80315776 0.80315776        nan 0.80315776 0.80351284\n",
            "        nan        nan 0.79942995        nan 0.7967688  0.80244791\n",
            " 0.80244791 0.80280267 0.80244791 0.80244791        nan        nan\n",
            "        nan        nan        nan 0.80315776 0.80315776        nan\n",
            " 0.80315776 0.80351284        nan        nan 0.8026249         nan\n",
            " 0.80067297 0.8015606  0.8015606  0.8017379  0.8015606  0.8015606\n",
            "        nan        nan        nan        nan        nan 0.80315776\n",
            " 0.80315776        nan 0.80315776 0.80351284        nan        nan\n",
            " 0.8017379         nan 0.80280315 0.80298014 0.80298014 0.80280283\n",
            " 0.80298014 0.80298014        nan        nan        nan        nan\n",
            "        nan 0.80315776 0.80315776        nan 0.80315776 0.80351284\n",
            "        nan        nan 0.80333538        nan 0.80298045 0.8036903\n",
            " 0.8036903  0.8036903  0.8036903  0.8036903         nan        nan\n",
            "        nan        nan        nan 0.80315776 0.80315776        nan\n",
            " 0.80315776 0.80351284        nan        nan 0.804223          nan\n",
            " 0.80422285 0.80440015 0.80440015 0.80440015 0.80440015 0.80440015\n",
            "        nan        nan        nan        nan        nan 0.80315776\n",
            " 0.80315776        nan 0.80315776 0.80351284        nan        nan\n",
            " 0.80457777        nan 0.80440031 0.80422285 0.80422285 0.80404523\n",
            " 0.80404523 0.80404523        nan        nan        nan        nan\n",
            "        nan 0.80315776 0.80315776        nan 0.80315776 0.80351284\n",
            "        nan        nan 0.80422285        nan 0.80422285 0.80351284\n",
            " 0.80351284 0.80351284 0.80351284 0.80386792        nan        nan\n",
            "        nan        nan        nan 0.80315776 0.80315776        nan\n",
            " 0.80315776 0.80351284        nan        nan 0.8036903         nan\n",
            " 0.8036903  0.8031576  0.8031576  0.8031576  0.8031576  0.80351284\n",
            "        nan        nan        nan        nan        nan 0.80315776\n",
            " 0.80315776        nan 0.80315776 0.80351284        nan        nan\n",
            " 0.80298014        nan 0.80351284 0.80262521 0.80262521 0.80262521\n",
            " 0.80262521 0.80369046        nan        nan        nan        nan\n",
            "        nan 0.80315776 0.80315776        nan 0.80315776 0.80351284\n",
            "        nan        nan 0.80262505        nan 0.80333522 0.80315776\n",
            " 0.80315776 0.80315776 0.80280267 0.80351284        nan        nan\n",
            "        nan        nan        nan 0.80315776 0.80315776        nan\n",
            " 0.80315776 0.80351284        nan        nan 0.80298014        nan\n",
            " 0.80351284 0.80315776 0.80315776 0.80315776 0.80315776 0.80351284\n",
            "        nan        nan        nan        nan        nan 0.80315776\n",
            " 0.80315776        nan 0.80315776 0.80351284        nan        nan\n",
            " 0.80298014        nan 0.80333522 0.80315776 0.80315776 0.80315776\n",
            " 0.80315776 0.80351284        nan        nan        nan        nan\n",
            "        nan 0.80315776 0.80315776        nan 0.80315776 0.80351284\n",
            "        nan        nan 0.80298014        nan 0.80351284 0.80315776\n",
            " 0.80315776 0.80315776 0.80315776 0.80333522        nan        nan\n",
            "        nan        nan        nan 0.80315776 0.80315776        nan\n",
            " 0.80315776 0.80351284        nan        nan 0.80298014        nan\n",
            " 0.80351284 0.80315776 0.80315776 0.80315776 0.80315776 0.80351284\n",
            "        nan        nan        nan        nan        nan 0.80315776\n",
            " 0.80315776        nan 0.80315776 0.80351284]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV(estimator=Pipeline(steps=[('preprocessor',\n",
            "                                        ColumnTransformer(transformers=[('num',\n",
            "                                                                         Pipeline(steps=[('scaler',\n",
            "                                                                                          StandardScaler())]),\n",
            "                                                                         Index(['seniorcitizen', 'tenure', 'monthlycharges', 'totalcharges'], dtype='object')),\n",
            "                                                                        ('cat',\n",
            "                                                                         Pipeline(steps=[('encoder',\n",
            "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
            "                                                                         Index(['gender', 'partner', 'dependents', 'phoneservice...\n",
            "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
            "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
            "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
            "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
            "                         'classifier__penalty': ['l1', 'l2', 'elasticnet',\n",
            "                                                 'none'],\n",
            "                         'classifier__solver': ['newton-cg', 'lbfgs',\n",
            "                                                'liblinear', 'sag', 'saga']},\n",
            "             scoring='accuracy')\n",
            "{'classifier__C': 4.281332398719396, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
            "Modelo regresión logística\n",
            "Accuracy: 0.8119233498935415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos el clasificador con características polinómicas\n",
        "logreg_base = LogisticRegression()\n",
        "clf_logreg_poly = Pipeline(steps=[(\"preprocessor\", preprocessor), ('poly', PolynomialFeatures(include_bias=False)),(\"classifier\", logreg_base)])\n",
        "\n",
        "param_grid = {\n",
        "    'poly__degree': list(range(2, 4)),\n",
        "    'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'classifier__C': np.logspace(-4, 4, 20),\n",
        "    'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "}\n",
        "\n",
        "search_logreg_poly = GridSearchCV(clf_logreg_poly, param_grid, scoring='accuracy', n_jobs=-1)\n",
        "search_logreg_poly.fit(X_train, y_train)\n",
        "print(search_logreg_poly)\n",
        "print(search_logreg_poly.best_params_)\n",
        "# Obtengamos el accuracy para la regresión logística con características polinómicas:\n",
        "print('Modelo regresión logística')\n",
        "print(f'Accuracy: {search_logreg_poly.score(X_test, y_test)}')"
      ],
      "metadata": {
        "id": "_bywtV1cL4ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos el clasificador basado en redes neuronales\n",
        "mlp_base = MLPClassifier()\n",
        "clf_mlp = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", mlp_base)])\n",
        "param_grid = {\n",
        "    \"classifier__hidden_layer_sizes\": [(50, 50), (100, 100), (50, 100, 50)],\n",
        "    \"classifier__activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
        "    #\"solver\": [\"adam\", \"sgd\"],\n",
        "    \"classifier__alpha\": np.logspace(-5, 3, 9),\n",
        "    \"classifier__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
        "    \"classifier__max_iter\": [200, 500, 1000]\n",
        "}\n",
        "search_mlp = GridSearchCV(clf_mlp, param_grid, scoring='accuracy', n_jobs=-1)\n",
        "search_mlp.fit(X_train, y_train)\n",
        "print(search_mlp)\n",
        "print(search_mlp.best_params_)\n",
        "# Obtengamos el accuracy de prueba para el MLP:\n",
        "print('Modelo regresión logística')\n",
        "print(f'Accuracy: {search_mlp.score(X_test, y_test)}')"
      ],
      "metadata": {
        "id": "yQoobK2sNzUr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}