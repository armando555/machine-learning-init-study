{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdmartinev/ST1613-AppliedML-/blob/main/Semana03/Regresi%C3%B3n_lineal_housing_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LHrUPpZW8ob",
        "outputId": "2dd47af8-27f8-4150-a2c5-b639fa86a30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-19 22:14:26--  https://docs.google.com/uc?export=download&id=1woWEpcwkCYSdRSTfSTT2j17JinrTMJOu\n",
            "Resolving docs.google.com (docs.google.com)... 172.253.122.101, 172.253.122.100, 172.253.122.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.253.122.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/q9ge8g16dk1n10eu4t74cipklqmg22ms/1681942425000/15315348669826032119/*/1woWEpcwkCYSdRSTfSTT2j17JinrTMJOu?e=download&uuid=190642a8-972b-4ed9-b96c-499dda903f03 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-19 22:14:26--  https://doc-10-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/q9ge8g16dk1n10eu4t74cipklqmg22ms/1681942425000/15315348669826032119/*/1woWEpcwkCYSdRSTfSTT2j17JinrTMJOu?e=download&uuid=190642a8-972b-4ed9-b96c-499dda903f03\n",
            "Resolving doc-10-6c-docs.googleusercontent.com (doc-10-6c-docs.googleusercontent.com)... 142.251.16.132, 2607:f8b0:4004:c17::84\n",
            "Connecting to doc-10-6c-docs.googleusercontent.com (doc-10-6c-docs.googleusercontent.com)|142.251.16.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1423529 (1.4M) [text/csv]\n",
            "Saving to: ‘housing.csv’\n",
            "\n",
            "housing.csv         100%[===================>]   1.36M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-04-19 22:14:26 (127 MB/s) - ‘housing.csv’ saved [1423529/1423529]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1woWEpcwkCYSdRSTfSTT2j17JinrTMJOu' -O housing.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K59ZRWp0XID6"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import HTML\n",
        "\n",
        "sys.path.append(\"code/.\")\n",
        "\n",
        "#import mglearn\n",
        "from IPython.display import display\n",
        "#from plotting_functions import *\n",
        "\n",
        "\n",
        "# Preprocessing and pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.stats import reciprocal\n",
        "\n",
        "# train test split and cross validation\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split, RandomizedSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import (\n",
        "    MinMaxScaler,\n",
        "    OneHotEncoder,\n",
        "    OrdinalEncoder,\n",
        "    StandardScaler,\n",
        "    PolynomialFeatures,\n",
        ")\n",
        "pd.set_option(\"display.max_colwidth\", 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0ag4DDlch9U"
      },
      "outputs": [],
      "source": [
        "random_state = 42\n",
        "np.random.seed(random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qikjVAQ7XQU0"
      },
      "outputs": [],
      "source": [
        "# Cargar los datos\n",
        "housing_df = pd.read_csv(\"housing.csv\")\n",
        "#Particiones\n",
        "train_df, test_df = train_test_split(housing_df, test_size=0.20, random_state=123)\n",
        "#Creación de nuevas variables\n",
        "train_df = train_df.assign(\n",
        "    rooms_per_household=train_df[\"total_rooms\"] / train_df[\"households\"]\n",
        ")\n",
        "\n",
        "test_df = test_df.assign(\n",
        "    rooms_per_household=test_df[\"total_rooms\"] / test_df[\"households\"]\n",
        ")\n",
        "\n",
        "train_df = train_df.assign(\n",
        "    bedrooms_per_household=train_df[\"total_bedrooms\"] / train_df[\"households\"]\n",
        ")\n",
        "\n",
        "test_df = test_df.assign(\n",
        "    bedrooms_per_household=test_df[\"total_bedrooms\"] / test_df[\"households\"]\n",
        ")\n",
        "\n",
        "train_df = train_df.assign(\n",
        "    population_per_household=train_df[\"population\"] / train_df[\"households\"]\n",
        ")\n",
        "\n",
        "test_df = test_df.assign(\n",
        "    population_per_household=test_df[\"population\"] / test_df[\"households\"]\n",
        ")\n",
        "#Definir características y variable objetivo\n",
        "X_train = train_df.drop(columns=[\"median_house_value\"])\n",
        "y_train = train_df[\"median_house_value\"]\n",
        "\n",
        "X_test = test_df.drop(columns=[\"median_house_value\"])\n",
        "y_test = test_df[\"median_house_value\"]\n",
        "\n",
        "#Encontrar variables numéricas y categóricas\n",
        "cat_cols = X_train.select_dtypes(include=object).columns\n",
        "num_cols = X_train.select_dtypes(include=np.number).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX9WzQnBXlz4"
      },
      "outputs": [],
      "source": [
        "#Definir el pipeline de pre-procesamiento\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),(\"scaler\", StandardScaler())]\n",
        ")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, num_cols),\n",
        "        (\"cat\", categorical_transformer, cat_cols),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definamos el regresor ridge\n",
        "ridge_base = Ridge()\n",
        "clf_ridge = Pipeline(steps=[(\"preprocessor\", preprocessor), ('poly', PolynomialFeatures(include_bias=True)), (\"regressor\", ridge_base)])\n",
        "# Definamos las distribuciones de parámetros sobre las que haremos la búsqueda:\n",
        "param_distributions = {\n",
        "    'poly__degree': list(range(1, 4)),\n",
        "    'regressor__alpha': reciprocal(1e-5, 1e3)\n",
        "}\n",
        "# Definamos nuestros modelos mediante RandomizedSearchCV:\n",
        "search_ridge = RandomizedSearchCV(\n",
        "    clf_ridge, \n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "#Entrenemos los modelos\n",
        "search_ridge.fit(X_train, y_train)\n",
        "print(search_ridge)\n",
        "print(search_ridge.best_params_)\n",
        "# Obtengamos el R^2 y el MAE de prueba para el modelo ridge:\n",
        "print('Modelo ridge')\n",
        "print(f'R^2: {search_ridge.score(X_test, y_test)}')\n",
        "print(f'MAE: {mean_absolute_error(y_test, search_ridge.predict(X_test))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yd7qFTschtN",
        "outputId": "ef5eb67f-6a1d-4c27-fee3-82b1203700b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Modelo ridge\n",
            "R^2: 0.6476159989658351\n",
            "MAE: 48978.12634480735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definamos el regresor lasso\n",
        "lasso_base = Lasso()\n",
        "clf_lasso = Pipeline(steps=[(\"preprocessor\", preprocessor), ('poly', PolynomialFeatures(include_bias=True)), (\"regressor\", lasso_base)])\n",
        "# Definamos las distribuciones de parámetros sobre las que haremos la búsqueda:\n",
        "param_distributions = {\n",
        "    'poly__degree': list(range(1, 4)),\n",
        "    'regressor__alpha': np.logspace(-4, 4, 20),  # Regularization strength; smaller values = weaker regularization\n",
        "}\n",
        "# Definamos nuestros modelos mediante RandomizedSearchCV:\n",
        "search_lasso = RandomizedSearchCV(\n",
        "    clf_lasso, \n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=4\n",
        ")\n",
        "#Entrenemos los modelos\n",
        "search_lasso.fit(X_train, y_train)\n",
        "print(search_lasso)\n",
        "print(search_lasso.best_params_)\n",
        "# Obtengamos el R^2 y el MAE de prueba para el modelo ridge:\n",
        "print('Modelo Lasso')\n",
        "print(f'R^2: {search_lasso.score(X_test, y_test)}')\n",
        "print(f'MAE: {mean_absolute_error(y_test, search_lasso.predict(X_test))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Oju52Dmh8xd",
        "outputId": "bcdbaa8c-039c-4055-91ad-8d716036d28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Modelo ridge\n",
            "R^2: 0.6476177498261906\n",
            "MAE: 48976.93150054957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+12, tolerance: 2.199e+10\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definamos el regresor Elastic-net\n",
        "elnet_base = ElasticNet()\n",
        "clf_elnet = Pipeline(steps=[(\"preprocessor\", preprocessor), ('poly', PolynomialFeatures(include_bias=True)), (\"regressor\", elnet_base)])\n",
        "# Definamos las distribuciones de parámetros sobre las que haremos la búsqueda:\n",
        "param_distributions = {\n",
        "    'poly__degree': list(range(1, 4)),\n",
        "    'regressor__alpha': np.logspace(-4, 4, 20),  # Regularization strength; smaller values = weaker regularization\n",
        "    'regressor__l1_ratio': np.linspace(0, 1, 10),  # Ratio for Elastic Net\n",
        "}\n",
        "# Definamos nuestros modelos mediante RandomizedSearchCV:\n",
        "search_elnet = RandomizedSearchCV(\n",
        "    clf_elnet, \n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "#Entrenemos los modelos\n",
        "search_elnet.fit(X_train, y_train)\n",
        "print(search_elnet)\n",
        "print(search_elnet.best_params_)\n",
        "# Obtengamos el R^2 y el MAE de prueba para el modelo ridge:\n",
        "print('Modelo Elastic net')\n",
        "print(f'R^2: {search_elnet.score(X_test, y_test)}')\n",
        "print(f'MAE: {mean_absolute_error(y_test, search_elnet.predict(X_test))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etHm2wU1jkr-",
        "outputId": "7ec33efa-164d-42c9-fdf7-28b8756d8e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Modelo ridge\n",
            "R^2: 0.6476671572815367\n",
            "MAE: 48984.56459126855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.133e+12, tolerance: 2.199e+10\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhisCOzWlUXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd4ea01-2f7d-40be-b256-670a70d0364c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Modelo ridge\n",
            "R^2: 0.7285636349519824\n",
            "MAE: 41705.67151704049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Definamos el regresor basado en redes neuronales\n",
        "mlp_base = MLPRegressor()\n",
        "clf_mlp = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"regressor\", mlp_base)])\n",
        "param_distributions = {\n",
        "    \"regressor__hidden_layer_sizes\": [(50, 50), (100, 100), (50, 100, 50)],\n",
        "    \"regressor__activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
        "    #\"solver\": [\"adam\", \"sgd\"],\n",
        "    \"regressor__alpha\": np.logspace(-5, 3, 9),\n",
        "    \"regressor__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
        "    \"regressor__max_iter\": [200, 500, 1000]\n",
        "}\n",
        "# Definamos nuestros modelos mediante RandomizedSearchCV:\n",
        "search_mlp = RandomizedSearchCV(\n",
        "    clf, \n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "#Entrenemos el modelo\n",
        "search_mlp.fit(X_train, y_train)\n",
        "# Obtengamos los mejores hiperparámetros encontrados para el modelo ridge\n",
        "search_mlp.best_params_\n",
        "# Obtengamos el R^2 y el MAE de prueba para el modelo ridge:\n",
        "print('Modelo ridge')\n",
        "print(f'R^2: {search_mlp.score(X_test, y_test)}')\n",
        "print(f'MAE: {mean_absolute_error(y_test, search_mlp.predict(X_test))}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzuAOc7q4S+Kkmp8/AtRkx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}